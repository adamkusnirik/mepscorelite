# MEP Ranking System - Folder Structure & Requirements

## ðŸ“ Project Directory Structure

```
mepranking/
â”œâ”€â”€ ðŸ“‚ data/                          # Data storage and processing
â”‚   â”œâ”€â”€ ðŸ“‚ parltrack/                 # â­ MAIN DATA UPDATE FOLDER
â”‚   â”‚   â”œâ”€â”€ ep_mep_activities.json.zst    # MEP activities (required)
â”‚   â”‚   â”œâ”€â”€ ep_amendments.json.zst        # Amendment details (required)
â”‚   â”‚   â”œâ”€â”€ ep_votes.json.zst             # Voting records (required)
â”‚   â”‚   â”œâ”€â”€ ep_meps.json.zst              # MEP info (required)
â”‚   â”‚   â””â”€â”€ [decompressed .json files]    # Auto-generated during processing
â”‚   â”œâ”€â”€ ðŸ“‚ parltrack backup/          # Historical data (Terms 8 & 9)
â”‚   â”œâ”€â”€ ðŸ“‚ term_list/                 # Official MEP lists per term
â”‚   â”‚   â”œâ”€â”€ 8th term_raw.csv
â”‚   â”‚   â”œâ”€â”€ 9th term_raw.csv
â”‚   â”‚   â””â”€â”€ 10th term_raw.csv
â”‚   â”œâ”€â”€ meps.db                       # SQLite database (generated)
â”‚   â””â”€â”€ sync_metadata.json            # Update tracking (generated)
â”‚
â”œâ”€â”€ ðŸ“‚ backend/                       # Data processing scripts
â”‚   â”œâ”€â”€ ingest_parltrack.py           # Step 1: Import raw data
â”‚   â”œâ”€â”€ build_term_dataset.py         # Step 2: Generate rankings
â”‚   â”œâ”€â”€ mep_ranking_scorer.py         # 4-category scoring system
â”‚   â”œâ”€â”€ outlier_based_scorer.py       # Statistical scoring methods
â”‚   â””â”€â”€ [other processing modules]
â”‚
â”œâ”€â”€ ðŸ“‚ public/                        # Frontend web application
â”‚   â”œâ”€â”€ ðŸ“‚ data/                      # Generated JSON datasets
â”‚   â”‚   â”œâ”€â”€ term10_dataset.json       # Current term rankings (auto-generated)
â”‚   â”‚   â”œâ”€â”€ term9_dataset.json        # Historical rankings
â”‚   â”‚   â””â”€â”€ term8_dataset.json        # Historical rankings
â”‚   â”œâ”€â”€ ðŸ“‚ js/                        # JavaScript modules
â”‚   â”‚   â”œâ”€â”€ app.js                    # Main application logic
â”‚   â”‚   â”œâ”€â”€ utilities.js              # Data loading functions
â”‚   â”‚   â”œâ”€â”€ profile.js                # MEP profile pages
â”‚   â”‚   â””â”€â”€ [other JS modules]
â”‚   â”œâ”€â”€ index.html                    # Main rankings page
â”‚   â”œâ”€â”€ profile.html                  # MEP profile template
â”‚   â””â”€â”€ methodology.html              # Scoring methodology docs
â”‚
â”œâ”€â”€ ðŸ“‚ agents/                        # AI agent system (optional)
â”œâ”€â”€ ðŸ“‚ logs/                          # System logs (generated)
â”œâ”€â”€ run_update.py                     # â­ MAIN UPDATE COMMAND
â”œâ”€â”€ run_update.bat                    # Windows update script
â”œâ”€â”€ launch_app.py                     # Application launcher
â””â”€â”€ requirements.txt                  # Python dependencies
```

## ðŸŽ¯ Data Update Requirements

### Essential Files for Updates

**Location**: `\data\parltrack\`

| File | Purpose | Required | Size (approx) |
|------|---------|----------|---------------|
| `ep_mep_activities.json.zst` | MEP activities (speeches, amendments, etc.) | âœ… Yes | ~50-100MB |
| `ep_amendments.json.zst` | Detailed amendment data | âœ… Yes | ~20-50MB |
| `ep_votes.json.zst` | Parliamentary voting records | âœ… Yes | ~10-30MB |
| `ep_meps.json.zst` | MEP biographical & political info | âœ… Yes | ~5-10MB |

**Total Download**: ~85-190MB compressed data

### Generated Files (Auto-Created)

| File/Folder | Generated By | Purpose |
|-------------|--------------|---------|
| `data/meps.db` | `ingest_parltrack.py` | SQLite database with processed data |
| `public/data/term10_dataset.json` | `build_term_dataset.py` | Frontend JSON dataset |
| Decompressed `.json` files | Update process | Working files from compressed data |

## ðŸ”„ Data Flow Process

```
1. ParlTrack Data (.zst files)
   â†“
2. Decompress & Validate
   â†“
3. Import to SQLite Database (meps.db)
   â†“
4. Apply 4-Category Scoring
   â†“
5. Generate Frontend JSON (term10_dataset.json)
   â†“
6. Update Profile Pages & Rankings
```

## ðŸ“‹ File Requirements Checklist

### Before Data Update
- [ ] All 4 required .zst files present in `\data\parltrack\`
- [ ] Files are recent (check timestamps)
- [ ] Sufficient disk space (500MB+ recommended)
- [ ] Python environment ready

### After Data Update
- [ ] `data/meps.db` updated (check file timestamp)
- [ ] `public/data/term10_dataset.json` refreshed
- [ ] MEP count matches official EP numbers
- [ ] No error messages in console output
- [ ] Web application loads correctly

## ðŸ—‚ï¸ File Management Best Practices

### Storage Management
- **Keep Original Files**: Always retain .zst files for backup
- **Archive Old Versions**: Move previous datasets to `backups/` folder
- **Monitor Disk Usage**: Large files can accumulate over time

### Version Control
- Track data update timestamps in `sync_metadata.json`
- Keep changelog of major MEP list changes
- Document significant parliamentary events affecting data

### Security & Access
- Protect database files from accidental deletion
- Regular backups of `data/meps.db`
- Maintain access logs for data updates

## âš ï¸ Critical Paths

**Never Delete These Folders:**
- `\data\parltrack\` - Main data folder
- `\public\data\` - Generated datasets
- `\backend\` - Processing scripts

**Safe to Clean:**
- `\logs\` - System logs (regenerated)
- `\cache\` - Temporary files
- Decompressed `.json` working files (regenerated from .zst)

## ðŸ”§ Troubleshooting File Issues

### Missing Files
```bash
# Check required files exist
ls data/parltrack/ep_*.zst

# Expected output: 4 files listed
```

### Permission Issues
- Ensure write access to `data/` folder
- Run updates with appropriate user permissions
- Check antivirus isn't blocking file access

### Disk Space Issues
- Minimum: 500MB free space required
- Recommended: 2GB for comfortable operation
- Monitor `data/` folder growth over time

## ðŸ“Š File Size Guidelines

### Normal Sizes (10th Term)
- **Database**: 50-200MB (`meps.db`)
- **Term Dataset**: 5-15MB (`term10_dataset.json`)
- **Log Files**: 1-5MB total

### Warning Signs
- Database >500MB (investigate data issues)
- JSON datasets >50MB (possible data bloat)
- Rapid file size growth (check for duplicates)

---

**Important**: The folder structure is designed for reliability and ease of maintenance. Following these guidelines ensures smooth data updates and system operation.